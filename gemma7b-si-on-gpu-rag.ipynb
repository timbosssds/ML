{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":8222635,"sourceType":"datasetVersion","datasetId":4874830},{"sourceId":11394,"sourceType":"modelInstanceVersion","modelInstanceId":8332}],"dockerImageVersionId":30665,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Copy from following link: https://www.kaggle.com/code/kingabzpro/gemma-7b-simple-inference-on-gpu\n        \nOther set ups have worked, but this has the lowest inference latency.\nPlan now is to: <br>\n\n__1.0 Hold: Add Gradio UI__ .... Don't think Gradio is very customisable + still having issues getting going. Might be easier to stick with fastapi/Uvicorn + Jijna/HTML\n\n__2.0 Add RAG__ (based on 4. Vertex deploy...)\n\n__3.0 UI for Playground__ (see 1.0) will be critical. 1st just need Q&A, then can expand to ingesting docs, but that adds obvious next steps (UI to support + backend to process)","metadata":{"execution":{"iopub.status.busy":"2024-03-15T12:53:41.281614Z","iopub.execute_input":"2024-03-15T12:53:41.281944Z","iopub.status.idle":"2024-03-15T12:54:35.192105Z","shell.execute_reply.started":"2024-03-15T12:53:41.281919Z","shell.execute_reply":"2024-03-15T12:54:35.190827Z"}}},{"cell_type":"markdown","source":"### -- Existing code from above link","metadata":{}},{"cell_type":"code","source":"%%capture\n%pip install -U bitsandbytes\n%pip install -U transformers\n%pip install -U accelerate","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:34:58.989438Z","iopub.execute_input":"2024-04-26T03:34:58.990110Z","iopub.status.idle":"2024-04-26T03:35:35.938119Z","shell.execute_reply.started":"2024-04-26T03:34:58.990068Z","shell.execute_reply":"2024-04-26T03:35:35.936933Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoConfig\n\nmodelName = \"/kaggle/input/gemma/transformers/7b-it/2\"\n\nbnbConfig = BitsAndBytesConfig(\n    load_in_4bit = True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.bfloat16,\n)\n\ntokenizer = AutoTokenizer.from_pretrained(modelName)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    modelName,\n    device_map = \"auto\",\n    quantization_config=bnbConfig\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-26T03:35:56.392070Z","iopub.execute_input":"2024-04-26T03:35:56.392736Z","iopub.status.idle":"2024-04-26T03:38:30.168146Z","shell.execute_reply.started":"2024-04-26T03:35:56.392701Z","shell.execute_reply":"2024-04-26T03:38:30.167080Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Gemma's activation function should be approximate GeLU and not exact GeLU.\nChanging the activation function to `gelu_pytorch_tanh`.if you want to use the legacy `gelu`, edit the `model.config` to set `hidden_activation=gelu`   instead of `hidden_act`. See https://github.com/huggingface/transformers/pull/29402 for more details.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b0dbac8732994cdabc2397a9cb01d9f6"}},"metadata":{}}]},{"cell_type":"code","source":"from IPython.display import Markdown, display\nsystem =  \"You are a skilled software engineer who consistently produces high-quality Python code.\"\nuser = \"Write a Python code to display text in a star pattern.\"\n\nprompt = f\"System: {system} \\n User: {user} \\n AI: \"\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\noutputs = model.generate(**inputs, max_length=500, num_return_sequences=1)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nMarkdown(text.split(\"AI:\")[1])","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:38:41.372822Z","iopub.execute_input":"2024-04-26T03:38:41.373336Z","iopub.status.idle":"2024-04-26T03:39:20.111601Z","shell.execute_reply.started":"2024-04-26T03:38:41.373306Z","shell.execute_reply":"2024-04-26T03:39:20.110604Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n2024-04-26 03:38:45.746078: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-26 03:38:45.746205: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-26 03:38:45.909688: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" \n\n```python\ndef star_pattern(n):\n    for row in range(n):\n        for col in range(n):\n            if (col == 0 or row == n - 1) and (row >= 1 and col >= 1):\n                print(\"*\", end=\" \")\n            else:\n                print(\" \", end=\" \")\n        print()\n\nstar_pattern(5)\n```\n\n**Explanation:**\n\n* The function `star_pattern` takes an integer `n` as input, representing the number of rows in the star pattern.\n* It uses nested loops to iterate over the rows and columns of the pattern.\n* The condition `(col == 0 or row == n - 1) and (row >= 1 and col >= 1)` checks if the current position is at the first column or the last row, and if the row and column positions are greater than or equal to 1.\n* If the condition above is true, it prints a star (`*`) followed by a space. Otherwise, it prints a space.\n* The loop prints a newline character (`\\n`) after each row of stars is printed.\n* Finally, the `star_pattern` function is called with an input of 5, which will produce the following star pattern:\n\n```\n    *\n   ***\n  *****\n *******\n```\n\n**Note:**\n\n* The code assumes that the input `n` will be an integer.\n* The number of stars printed in each row increases by one from the previous row.\n* The spacing between the stars is one space.\n* The stars are printed in the center of the row."},"metadata":{}}]},{"cell_type":"markdown","source":"### -- RAG set up","metadata":{}},{"cell_type":"code","source":"# --- Install lib\n#!pip3 install --upgrade google-cloud-aiplatform\n#!pip3 install ipython pandas[output_formatting] google-cloud-language==2.10.0\n!pip install langchain\n!pip install PyPDF2\n!pip install pypdf\n!pip install sentence_transformers\n!pip install torch\n!pip install pandas\n!pip install pdfplumber","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:39:27.433673Z","iopub.execute_input":"2024-04-26T03:39:27.434267Z","iopub.status.idle":"2024-04-26T03:41:05.431113Z","shell.execute_reply.started":"2024-04-26T03:39:27.434238Z","shell.execute_reply":"2024-04-26T03:41:05.429729Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting langchain\n  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.25)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.1)\nRequirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.6.4)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.33)\nCollecting langchain-community<0.1,>=0.0.32 (from langchain)\n  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\nCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\nCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl.metadata (2.0 kB)\nCollecting langsmith<0.2.0,>=0.1.17 (from langchain)\n  Downloading langsmith-0.1.51-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.4)\nRequirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.5.3)\nRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\nRequirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.2.3)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\nRequirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\nCollecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\nCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m797.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\nRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\nDownloading langchain-0.1.16-py3-none-any.whl (817 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.0.34-py3-none-any.whl (1.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_core-0.1.46-py3-none-any.whl (299 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.3/299.3 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\nDownloading langsmith-0.1.51-py3-none-any.whl (115 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.0/116.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-23.2-py3-none-any.whl (53 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, orjson, langsmith, langchain-core, langchain-text-splitters, langchain-community, langchain\n  Attempting uninstall: packaging\n    Found existing installation: packaging 21.3\n    Uninstalling packaging-21.3:\n      Successfully uninstalled packaging-21.3\n  Attempting uninstall: orjson\n    Found existing installation: orjson 3.9.10\n    Uninstalling orjson-3.9.10:\n      Successfully uninstalled orjson-3.9.10\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 23.8.0 requires cubinlinker, which is not installed.\ncudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 23.8.0 requires ptxcompiler, which is not installed.\ncuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\nkeras-cv 0.8.2 requires keras-core, which is not installed.\nkeras-nlp 0.8.1 requires keras-core, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 11.0.0 which is incompatible.\ncudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\ncudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ncudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\ncuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cuda 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ndask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\ndistributed 2023.7.1 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\ngoogle-cloud-bigquery 2.34.4 requires packaging<22.0dev,>=14.3, but you have packaging 23.2 which is incompatible.\njupyterlab 4.1.2 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.0.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\nlibpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\nmomepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\nosmnx 1.9.1 requires shapely>=2.0, but you have shapely 1.8.5.post1 which is incompatible.\nraft-dask 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\nspopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.0.5 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed langchain-0.1.16 langchain-community-0.0.34 langchain-core-0.1.46 langchain-text-splitters-0.0.1 langsmith-0.1.51 orjson-3.10.1 packaging-23.2\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting PyPDF2\n  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\nDownloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyPDF2\nSuccessfully installed PyPDF2-3.0.1\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pypdf in /opt/conda/lib/python3.10/site-packages (4.0.2)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting sentence_transformers\n  Downloading sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: transformers<5.0.0,>=4.34.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.40.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (4.66.1)\nRequirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (2.1.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.26.4)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (1.11.4)\nRequirement already satisfied: huggingface-hub>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (0.20.3)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence_transformers) (9.5.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2024.2.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.9.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.15.1->sentence_transformers) (23.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.2)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence_transformers) (3.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\nDownloading sentence_transformers-2.7.0-py3-none-any.whl (171 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.5/171.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0mm\n\u001b[?25hInstalling collected packages: sentence_transformers\nSuccessfully installed sentence_transformers-2.7.0\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.1.4)\nRequirement already satisfied: numpy<2,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","output_type":"stream"},{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"Collecting pdfplumber\n  Downloading pdfplumber-0.11.0-py3-none-any.whl.metadata (39 kB)\nCollecting pdfminer.six==20231228 (from pdfplumber)\n  Downloading pdfminer.six-20231228-py3-none-any.whl.metadata (4.2 kB)\nRequirement already satisfied: Pillow>=9.1 in /opt/conda/lib/python3.10/site-packages (from pdfplumber) (9.5.0)\nCollecting pypdfium2>=4.18.0 (from pdfplumber)\n  Downloading pypdfium2-4.29.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (3.3.2)\nRequirement already satisfied: cryptography>=36.0.0 in /opt/conda/lib/python3.10/site-packages (from pdfminer.six==20231228->pdfplumber) (41.0.7)\nRequirement already satisfied: cffi>=1.12 in /opt/conda/lib/python3.10/site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.16.0)\nRequirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.21)\nDownloading pdfplumber-0.11.0-py3-none-any.whl (56 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pdfminer.six-20231228-py3-none-any.whl (5.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading pypdfium2-4.29.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\nSuccessfully installed pdfminer.six-20231228 pdfplumber-0.11.0 pypdfium2-4.29.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# --- Ingest and chunk data (now using new doc ingestion)\n\n# Uses same loader as above, but now works for multiple docs\n#from langchain.document_loaders import PDFPlumberLoader\nimport os as os\nimport pandas as pd\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nimport pdfplumber\nfrom langchain.document_loaders import PDFPlumberLoader\n\ndef load_pdfs_from_directory(directory_path):\n    docs = []\n    for filename in os.listdir(directory_path):\n        if filename.endswith(\".pdf\"):\n            file_path = os.path.join(directory_path, filename)\n            loader = PDFPlumberLoader(file_path)\n            loaded_docs = loader.load()\n            \n            #text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n            text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=250)\n            \n            for doc in loaded_docs:\n                texts = text_splitter.split_text(doc.page_content)\n                for text in texts:\n                    docs.append({\n                        'page_content': text,\n                        'metadata': doc.metadata\n                    })\n    return docs\n\n#directory_path = \"/home/jupyter/pdf\"\ndirectory_path = \"/kaggle/input/benpayfactsandcs/\"\nall_pdf_docs = load_pdfs_from_directory(directory_path)\n\ndata = all_pdf_docs\ndf = pd.DataFrame(data)\n\n\ndf['len'] = df['page_content'].str.len()\n\ndf1 = df.copy()\n\ndf1['page_content_data'] = df1['page_content']\ndf1['page_content'] = df1['page_content'].str.replace('\\n', '')\n\ndf2 = pd.json_normalize(df1.metadata)\ndf1 = pd.concat([df1, df2], axis=1)\ndf1['source'] = df1['source'].str.replace('/kaggle/input/benpayfactsandcs/', '')\n#/kaggle/input/benpayfactsandcs/bendigo-payment-facilities-terms-conditions.pdf\n\ndf1['pagestr'] = df1['page'].astype(str)\n\ndf1['page_content_plus'] = df1['page_content'] + '[' + 'Source: ' + df1['source'] + ' page: ' + df1['pagestr'] + ']'\n\n#df1.drop(['metadata'], axis=1, inplace=True)\n# df1.drop(['metadata', 'total_pages', 'Creator', 'Producer', 'CreationDate', 'ModDate', 'Author', 'ContentTypeId', '_dlc_DocIdItemGuid',\\\n#            'PADocID', 'MediaServiceImageTags', 'Company', 'file_path', 'source', 'Subject', 'Keywords'], axis=1, inplace=True)\n \ndisplay(df1.head(2))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:00:43.206795Z","iopub.execute_input":"2024-04-26T06:00:43.207642Z","iopub.status.idle":"2024-04-26T06:00:56.035951Z","shell.execute_reply.started":"2024-04-26T06:00:43.207610Z","shell.execute_reply":"2024-04-26T06:00:56.034938Z"},"trusted":true},"execution_count":73,"outputs":[{"output_type":"display_data","data":{"text/plain":"                         page_content                            metadata  \\\n0  Bendigo Payment FacilitiesTerms...  {'source': '/kaggle/input/benpa...   \n1  ContentsBendigo Payment Facilit...  {'source': '/kaggle/input/benpa...   \n\n   len                   page_content_data  \\\n0   63  Bendigo Payment Facilities\\nTer...   \n1  885  Contents\\nBendigo Payment Facil...   \n\n                               source                           file_path  \\\n0  bendigo-payment-facilities-term...  /kaggle/input/benpayfactsandcs/...   \n1  bendigo-payment-facilities-term...  /kaggle/input/benpayfactsandcs/...   \n\n   page  total_pages           Creator          Producer  ...         Author  \\\n0     0           50  Power PDF Create  Power PDF Create  ...  Bianca Pisoni   \n1     1           50  Power PDF Create  Power PDF Create  ...  Bianca Pisoni   \n\n                                Title                       ContentTypeId  \\\n0  Bendigo-payment-facilities-term...  0x010100E809092CA74C4245B60BDAE...   \n1  Bendigo-payment-facilities-term...  0x010100E809092CA74C4245B60BDAE...   \n\n                   _dlc_DocIdItemGuid     PADocID MediaServiceImageTags  \\\n0  da16ccf0-5d9b-4890-8741-29ad993...  39175925v1                         \n1  da16ccf0-5d9b-4890-8741-29ad993...  39175925v1                         \n\n                              Subject                            Keywords  \\\n0  personal-payment-facilities-ter...  personal-payment-facilities-ter...   \n1  personal-payment-facilities-ter...  personal-payment-facilities-ter...   \n\n  pagestr                   page_content_plus  \n0       0  Bendigo Payment FacilitiesTerms...  \n1       1  ContentsBendigo Payment Facilit...  \n\n[2 rows x 22 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_content</th>\n      <th>metadata</th>\n      <th>len</th>\n      <th>page_content_data</th>\n      <th>source</th>\n      <th>file_path</th>\n      <th>page</th>\n      <th>total_pages</th>\n      <th>Creator</th>\n      <th>Producer</th>\n      <th>...</th>\n      <th>Author</th>\n      <th>Title</th>\n      <th>ContentTypeId</th>\n      <th>_dlc_DocIdItemGuid</th>\n      <th>PADocID</th>\n      <th>MediaServiceImageTags</th>\n      <th>Subject</th>\n      <th>Keywords</th>\n      <th>pagestr</th>\n      <th>page_content_plus</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bendigo Payment FacilitiesTerms...</td>\n      <td>{'source': '/kaggle/input/benpa...</td>\n      <td>63</td>\n      <td>Bendigo Payment Facilities\\nTer...</td>\n      <td>bendigo-payment-facilities-term...</td>\n      <td>/kaggle/input/benpayfactsandcs/...</td>\n      <td>0</td>\n      <td>50</td>\n      <td>Power PDF Create</td>\n      <td>Power PDF Create</td>\n      <td>...</td>\n      <td>Bianca Pisoni</td>\n      <td>Bendigo-payment-facilities-term...</td>\n      <td>0x010100E809092CA74C4245B60BDAE...</td>\n      <td>da16ccf0-5d9b-4890-8741-29ad993...</td>\n      <td>39175925v1</td>\n      <td></td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>0</td>\n      <td>Bendigo Payment FacilitiesTerms...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ContentsBendigo Payment Facilit...</td>\n      <td>{'source': '/kaggle/input/benpa...</td>\n      <td>885</td>\n      <td>Contents\\nBendigo Payment Facil...</td>\n      <td>bendigo-payment-facilities-term...</td>\n      <td>/kaggle/input/benpayfactsandcs/...</td>\n      <td>1</td>\n      <td>50</td>\n      <td>Power PDF Create</td>\n      <td>Power PDF Create</td>\n      <td>...</td>\n      <td>Bianca Pisoni</td>\n      <td>Bendigo-payment-facilities-term...</td>\n      <td>0x010100E809092CA74C4245B60BDAE...</td>\n      <td>da16ccf0-5d9b-4890-8741-29ad993...</td>\n      <td>39175925v1</td>\n      <td></td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>1</td>\n      <td>ContentsBendigo Payment Facilit...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2 rows × 22 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# --- Embedd and store (once RAG working, replace storage from df to cloudSQL)\npd.set_option('display.max_colwidth', 35)\nimport pandas as pd\nimport numpy as np\nfrom sentence_transformers import SentenceTransformer\n\n# Load the Sentence Transformer model\n#model_trans = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\nmodel_trans = SentenceTransformer('sentence-transformers/all-mpnet-base-v2') # supposedly more powerful that above\n\n# Embed the chunked text\nembeddings = model_trans.encode(df1['page_content'])\n\n# Convert embedding vectors into one-dimensional arrays\none_dimensional_embeddings = []\nfor embedding in embeddings:\n    one_dimensional_embedding = np.ravel(embedding)\n    one_dimensional_embeddings.append(one_dimensional_embedding)\n\n# Combine the original text and embeddings into a DataFrame\ndata = {\n    \"original_text\": df1['page_content'],\n    \"embeddings\": one_dimensional_embeddings\n}\n\ndfe = pd.DataFrame(data)\ndf3 = pd.concat([df1, dfe], axis=1)\ndf3.drop(['original_text'], axis=1, inplace=True)\ndisplay(df3.head(3))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:15:52.093622Z","iopub.execute_input":"2024-04-26T06:15:52.094022Z","iopub.status.idle":"2024-04-26T06:15:59.369379Z","shell.execute_reply.started":"2024-04-26T06:15:52.093993Z","shell.execute_reply":"2024-04-26T06:15:59.368521Z"},"trusted":true},"execution_count":78,"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91b879e50a684b29aa2dca02c8d131a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e6240cb02cde4fdb9f753341e558f162"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e95c0a1a5fb1459f96ea55ac1a19d7dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c683e406bb72498c85ae6702f5c7e314"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0867fac1caa443f398de23ff09193efd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5fd22d452adb47798097e65e9e67e9b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe767107a27d46059933e2e68849afef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88c5708434f94ef2a4d3d3da095df485"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"38947bf7d1324029a8aacdfa2cfc4a73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6b7df5649f764da8a7507ee016eb2e71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78cd7d1b07b24a72a3f2701a6ee27e63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7504c3bda94d7091f8840200bb63a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"                         page_content                            metadata  \\\n0  Bendigo Payment FacilitiesTerms...  {'source': '/kaggle/input/benpa...   \n1  ContentsBendigo Payment Facilit...  {'source': '/kaggle/input/benpa...   \n2  Bendigo Payment Facilities Term...  {'source': '/kaggle/input/benpa...   \n\n   len                   page_content_data  \\\n0   63  Bendigo Payment Facilities\\nTer...   \n1  885  Contents\\nBendigo Payment Facil...   \n2  920  Bendigo Payment Facilities Term...   \n\n                               source                           file_path  \\\n0  bendigo-payment-facilities-term...  /kaggle/input/benpayfactsandcs/...   \n1  bendigo-payment-facilities-term...  /kaggle/input/benpayfactsandcs/...   \n2  bendigo-payment-facilities-term...  /kaggle/input/benpayfactsandcs/...   \n\n   page  total_pages           Creator          Producer  ...  \\\n0     0           50  Power PDF Create  Power PDF Create  ...   \n1     1           50  Power PDF Create  Power PDF Create  ...   \n2     2           50  Power PDF Create  Power PDF Create  ...   \n\n                                Title                       ContentTypeId  \\\n0  Bendigo-payment-facilities-term...  0x010100E809092CA74C4245B60BDAE...   \n1  Bendigo-payment-facilities-term...  0x010100E809092CA74C4245B60BDAE...   \n2  Bendigo-payment-facilities-term...  0x010100E809092CA74C4245B60BDAE...   \n\n                   _dlc_DocIdItemGuid     PADocID MediaServiceImageTags  \\\n0  da16ccf0-5d9b-4890-8741-29ad993...  39175925v1                         \n1  da16ccf0-5d9b-4890-8741-29ad993...  39175925v1                         \n2  da16ccf0-5d9b-4890-8741-29ad993...  39175925v1                         \n\n                              Subject                            Keywords  \\\n0  personal-payment-facilities-ter...  personal-payment-facilities-ter...   \n1  personal-payment-facilities-ter...  personal-payment-facilities-ter...   \n2  personal-payment-facilities-ter...  personal-payment-facilities-ter...   \n\n  pagestr                   page_content_plus  \\\n0       0  Bendigo Payment FacilitiesTerms...   \n1       1  ContentsBendigo Payment Facilit...   \n2       2  Bendigo Payment Facilities Term...   \n\n                           embeddings  \n0  [-0.009844421, 0.0152423745, 0....  \n1  [0.014502276, -0.021184146, 0.0...  \n2  [-0.0067184865, -0.04306116, 0....  \n\n[3 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>page_content</th>\n      <th>metadata</th>\n      <th>len</th>\n      <th>page_content_data</th>\n      <th>source</th>\n      <th>file_path</th>\n      <th>page</th>\n      <th>total_pages</th>\n      <th>Creator</th>\n      <th>Producer</th>\n      <th>...</th>\n      <th>Title</th>\n      <th>ContentTypeId</th>\n      <th>_dlc_DocIdItemGuid</th>\n      <th>PADocID</th>\n      <th>MediaServiceImageTags</th>\n      <th>Subject</th>\n      <th>Keywords</th>\n      <th>pagestr</th>\n      <th>page_content_plus</th>\n      <th>embeddings</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Bendigo Payment FacilitiesTerms...</td>\n      <td>{'source': '/kaggle/input/benpa...</td>\n      <td>63</td>\n      <td>Bendigo Payment Facilities\\nTer...</td>\n      <td>bendigo-payment-facilities-term...</td>\n      <td>/kaggle/input/benpayfactsandcs/...</td>\n      <td>0</td>\n      <td>50</td>\n      <td>Power PDF Create</td>\n      <td>Power PDF Create</td>\n      <td>...</td>\n      <td>Bendigo-payment-facilities-term...</td>\n      <td>0x010100E809092CA74C4245B60BDAE...</td>\n      <td>da16ccf0-5d9b-4890-8741-29ad993...</td>\n      <td>39175925v1</td>\n      <td></td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>0</td>\n      <td>Bendigo Payment FacilitiesTerms...</td>\n      <td>[-0.009844421, 0.0152423745, 0....</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ContentsBendigo Payment Facilit...</td>\n      <td>{'source': '/kaggle/input/benpa...</td>\n      <td>885</td>\n      <td>Contents\\nBendigo Payment Facil...</td>\n      <td>bendigo-payment-facilities-term...</td>\n      <td>/kaggle/input/benpayfactsandcs/...</td>\n      <td>1</td>\n      <td>50</td>\n      <td>Power PDF Create</td>\n      <td>Power PDF Create</td>\n      <td>...</td>\n      <td>Bendigo-payment-facilities-term...</td>\n      <td>0x010100E809092CA74C4245B60BDAE...</td>\n      <td>da16ccf0-5d9b-4890-8741-29ad993...</td>\n      <td>39175925v1</td>\n      <td></td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>1</td>\n      <td>ContentsBendigo Payment Facilit...</td>\n      <td>[0.014502276, -0.021184146, 0.0...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Bendigo Payment Facilities Term...</td>\n      <td>{'source': '/kaggle/input/benpa...</td>\n      <td>920</td>\n      <td>Bendigo Payment Facilities Term...</td>\n      <td>bendigo-payment-facilities-term...</td>\n      <td>/kaggle/input/benpayfactsandcs/...</td>\n      <td>2</td>\n      <td>50</td>\n      <td>Power PDF Create</td>\n      <td>Power PDF Create</td>\n      <td>...</td>\n      <td>Bendigo-payment-facilities-term...</td>\n      <td>0x010100E809092CA74C4245B60BDAE...</td>\n      <td>da16ccf0-5d9b-4890-8741-29ad993...</td>\n      <td>39175925v1</td>\n      <td></td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>personal-payment-facilities-ter...</td>\n      <td>2</td>\n      <td>Bendigo Payment Facilities Term...</td>\n      <td>[-0.0067184865, -0.04306116, 0....</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 23 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Vertex code. Replaced with next cell to run in Kaggle\n# --- Embed question (once all running, convert this and most other code to functions (or a class))\n# from sentence_transformers import SentenceTransformer\n# import numpy as np\n# import pandas as pd\n\n# # Initialize the Sentence Transformer model\n# model = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n\n# question = \"can the Easy Money Card be used overseas?\"\n\n# # Embed the question\n# embeddings = model.encode([question])\n\n# # Flatten the embedding list into a one-dimensional array\n# one_dimensional_embeddings = np.ravel(embeddings)\n\n# # Convert array to a single-row dataframe\n# df_question = pd.DataFrame({'embeddings': [one_dimensional_embeddings]})\n\n# df_question['question'] = question\n# df_question = df_question[['question','embeddings']]\n# display(df_question)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T06:56:37.116847Z","iopub.status.idle":"2024-04-25T06:56:37.117645Z","shell.execute_reply.started":"2024-04-25T06:56:37.117417Z","shell.execute_reply":"2024-04-25T06:56:37.117435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Can skip the next 3 as they are combined in the 4th as a single function","metadata":{}},{"cell_type":"code","source":"# --- Embed question (once all running, convert this and most other code to functions (or a class))\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\nimport numpy as np\n\n# Initialize the Sentence Transformer model\nmodel_trans = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\nquestion = \"can the Easy Money Card be used overseas?\"\n\n# Embed the question \n# -- (1st line is what i have been using in Vertex)\n#question_embedding = model.encode(question, convert_to_tensor=True)\n# -- had to replace with this to resolve error\n# Solution was to: Encode the question and move the tensor to the CPU\nquestion_embedding = model_trans.encode(question, convert_to_tensor=True).cpu()\n\n# Calculate the similarities\nsimilarities = df3['embeddings'].apply(lambda x: np.dot(question_embedding, x))\n\n# Identify the 3 most similar rows\nmost_similar_indices = similarities.nlargest(8).index\nmost_similar_rows = df3.iloc[most_similar_indices]\n\n# Display the most similar rows\ndisplay(most_similar_rows)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T03:43:51.876003Z","iopub.execute_input":"2024-04-26T03:43:51.876360Z","iopub.status.idle":"2024-04-26T03:43:53.414401Z","shell.execute_reply.started":"2024-04-26T03:43:51.876329Z","shell.execute_reply":"2024-04-26T03:43:53.413235Z"},"trusted":true},"execution_count":9,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[9], line 15\u001b[0m\n\u001b[1;32m      8\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcan the Easy Money Card be used overseas?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Embed the question \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# -- (1st line is what i have been using in Vertex)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#question_embedding = model.encode(question, convert_to_tensor=True)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# -- had to replace with this to resolve error\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Solution was to: Encode the question and move the tensor to the CPU\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m question_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m(question, convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Calculate the similarities\u001b[39;00m\n\u001b[1;32m     18\u001b[0m similarities \u001b[38;5;241m=\u001b[39m df3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mdot(question_embedding, x))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","\u001b[0;31mAttributeError\u001b[0m: 'GemmaForCausalLM' object has no attribute 'encode'"],"ename":"AttributeError","evalue":"'GemmaForCausalLM' object has no attribute 'encode'","output_type":"error"}]},{"cell_type":"code","source":"# Vertex code\n# cont = most_similar_rows['page_content_data'].tolist()\n# context = cont\n\n# # ------------------------\n\n# # prompt source: https://www.kaggle.com/code/gpreda/exploring-eu-ai-act-with-gemma/\n# prompt = f\"\"\"\n# You are an AI Agent specialized to answer to questions about the context provided.\n# In order to create the answer, please only use the information from the\n# context provided (Context). Do not include other information.\n# Answer with simple words.\n# If needed, include also explanations.\n# Question: {question}\n# Context: {context}\n# Answer:\n# \"\"\"\n\n# instances = [\n#     {\n#         \"prompt\": prompt,\n#         \"max_tokens\": 100, #100\n#         \"temperature\": 0.25, #0.15\n#         \"top_p\": 0.025, # 1.0\n#         \"top_k\": 40, #10\n#         #\"raw_response\": False,\n#         \"raw_response\": True,\n#     },\n# ]\n# response = endpoint_vllm.predict(instances=instances)\n# prediction = response.predictions[0]\n# print(prediction)","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:11:02.765749Z","iopub.execute_input":"2024-04-25T07:11:02.766479Z","iopub.status.idle":"2024-04-25T07:11:03.487926Z","shell.execute_reply.started":"2024-04-25T07:11:02.766442Z","shell.execute_reply":"2024-04-25T07:11:03.486763Z"},"trusted":true},"execution_count":8,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[8], line 29\u001b[0m\n\u001b[1;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124mYou are an AI Agent specialized to answer to questions about the context provided.\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mIn order to create the answer, please only use the information from the\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mAnswer:\u001b[39m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m     18\u001b[0m instances \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     {\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     27\u001b[0m     },\n\u001b[1;32m     28\u001b[0m ]\n\u001b[0;32m---> 29\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mendpoint_vllm\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(instances\u001b[38;5;241m=\u001b[39minstances)\n\u001b[1;32m     30\u001b[0m prediction \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mpredictions[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(prediction)\n","\u001b[0;31mNameError\u001b[0m: name 'endpoint_vllm' is not defined"],"ename":"NameError","evalue":"name 'endpoint_vllm' is not defined","output_type":"error"}]},{"cell_type":"code","source":"from IPython.display import Markdown, display\n\ncont = most_similar_rows['page_content_data'].tolist()\ncontext = cont\n\n#system =  \"You are a skilled software engineer who consistently produces high-quality Python code.\"\nsystem = f\"\"\"You are an AI Agent specialized to answer to questions about the context provided.\\\nIn order to create the answer, please only use the information from the\\\ncontext provided (Context). Do not include other information.\\\nAnswer with simple words.\\\nIf needed, include also explanations.\\\nContext: {context}\"\"\"\n\n#user = \"Write a Python code to display text in a star pattern.\"\n#user = question\nuser = \"can Foreign Currency Transactions performed?\"\n\nprompt = f\"System: {system} \\n User: {user} \\n AI: \"\n    \ninputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\n#outputs = model.generate(**inputs, max_length=1500, temperature = 0.25, num_return_sequences=1)\noutputs = model.generate(**inputs, max_length=1500, temperature = 0.25, top_p = 0.025, top_k = 40, \\\n                         num_return_sequences=1, do_sample=True)\n\ntext = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\nMarkdown(text.split(\"AI:\")[1])","metadata":{"execution":{"iopub.status.busy":"2024-04-25T07:14:54.043405Z","iopub.execute_input":"2024-04-25T07:14:54.043781Z","iopub.status.idle":"2024-04-25T07:15:07.088811Z","shell.execute_reply.started":"2024-04-25T07:14:54.043752Z","shell.execute_reply":"2024-04-25T07:15:07.087760Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":" \n\nSure, here is the answer to the user's question:\n\nForeign Currency Transactions performed using your Debit Card which are performed in currencies other than Australian dollars (AUD) are converted to Australian dollars (AUD) by the relevant Card Scheme using its relevant exchange rates and conversion process. As set out in the Schedule of Fees, Charges and Transaction Account Rebates, an International Fee applies to all Foreign Currency Transactions."},"metadata":{}}]},{"cell_type":"markdown","source":"# Below is the function that replaces the above 3","metadata":{}},{"cell_type":"code","source":"# -- Above 3 cells combined to function (but keeping above 3 if I need to work on the separately)\n\n# Above cell, converted to function\nimport numpy as np\nimport pandas as pd\nfrom sentence_transformers import SentenceTransformer\n\ndef answer_question(user, df3):\n    question_embedding = model_trans.encode(user, convert_to_tensor=True).cpu()\n    similarities = df3['embeddings'].apply(lambda x: np.dot(question_embedding, x))\n    \n    #most_similar_indices = similarities.nlargest(8).index\n    most_similar_indices = similarities.nlargest(4).index\n    \n    most_similar_rows = df3.iloc[most_similar_indices]\n\n    cont = most_similar_rows['page_content_data'].tolist()\n    context = ' '.join(cont)\n\n#     # -- Inference (Vertex version)\n#     system = f\"\"\"You are an AI Agent specialized to answer to questions about the context provided.\\\n#     In order to create the answer, please only use the information from the\\\n#     context provided (Context). Do not include other information.\\\n#     Answer with simple words.\\\n#     If needed, include also explanations.\\\n#     Context: {context}\"\"\"\n    \n    #     # -- Inference (Kaggle 1)\n    system = f\"\"\"You are an AI Agent specialized to answer to questions about the context provided.\\\n    In order to create the answer, please only use the information from the\\\n    context provided (Context). Do not include other information.\\\n    Context: {context}\"\"\"\n    \n        # -- Inference (KAggle 2)\n#     #system = f\"\"\"You are an AI Agent specialized to answer to questions about the context provided.\\\n#     system = f\"\"\"You are an AI Agent specialized in finding the passages of text in {context} that most accurately answer questions you receive.\\\n#                  Your task is then to answer the question using only passages you located and not any other information.\"\"\"\n\n    #user = \"Write a Python code to display text in a star pattern.\"\n    #user = question\n    #user = \"can Foreign Currency Transactions performed?\"\n\n    prompt = f\"System: {system} \\n User: {user} \\n AI: \"\n\n    inputs = tokenizer(prompt, return_tensors='pt', padding=True, truncation=True).to(\"cuda\")\n\n    #outputs = model.generate(**inputs, max_length=1500, temperature = 0.25, num_return_sequences=1)\n    #outputs = model.generate(**inputs, max_length=1500, temperature = 0.25, top_p = 0.025, top_k = 40, num_return_sequences=1, do_sample=True)\n    #outputs = model.generate(**inputs, max_length=1500, temperature = 0.15, top_p = 1.0, top_k = 10, num_return_sequences=1, do_sample=True)\n    \n    outputs = model.generate(**inputs, max_new_tokens=1500, temperature = 0.10, top_p = 1.0, top_k = 12, num_return_sequences=1, do_sample=True)\n\n    text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n\n    #Markdown(text.split(\"AI:\")[1])\n    out1 = (text.split(\"AI:\")[1])\n    return out1\n    return context\n\n#user = \"who is liable for unauthorised transactions?\"\n#user = \"can Foreign Currency Transactions be performed?\"\n#user = \"How do you process pay anyone payments?\"\nuser = \"What happens if accidently entered the incorrect amount for my pay anyone payments?\"\nprint(answer_question(user, df3))","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:17:34.241337Z","iopub.execute_input":"2024-04-26T06:17:34.241727Z","iopub.status.idle":"2024-04-26T06:17:55.590799Z","shell.execute_reply.started":"2024-04-26T06:17:34.241697Z","shell.execute_reply":"2024-04-26T06:17:55.589831Z"},"trusted":true},"execution_count":80,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ce497939955f4c7494c4c5c95e809f47"}},"metadata":{}},{"name":"stdout","text":" \n\nIf you accidentally entered the incorrect amount for your Pay Anyone payments, there are two possible scenarios:\n\n**1. Excess Payment:**\nIf the amount you told us to pay was greater than the amount you needed to pay, you must contact the recipient to obtain a refund of the excess. If we processed the Pay Anyone payment as an Osko Payment or a Fast Payment, we may be able to request that the funds, or just the overpaid amount, be returned on your behalf if you ask us to do so. However, the amount will not be returned to you unless the recipient consents to their financial institution returning the funds to us and we receive the returned funds.\n\n**2. Less Payment:**\nIf the amount you told us to pay was less than the amount you needed to pay, you can make another Pay Anyone payment for the difference.\n\nPlease note that these scenarios do not include BPAY payments. If you have made a mistaken BPAY Payment, please refer to the separate section on BPAY Payments below.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract of code from above to view context\nquestion_embedding = model_trans.encode(user, convert_to_tensor=True).cpu()\nsimilarities = df3['embeddings'].apply(lambda x: np.dot(question_embedding, x))\nmost_similar_indices = similarities.nlargest(4).index\nmost_similar_rows = df3.iloc[most_similar_indices]\ncont = most_similar_rows['page_content_data'].tolist()\ncontext = ' '.join(cont)\nprint (context)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:18:24.767540Z","iopub.execute_input":"2024-04-26T06:18:24.768261Z","iopub.status.idle":"2024-04-26T06:18:24.823486Z","shell.execute_reply.started":"2024-04-26T06:18:24.768225Z","shell.execute_reply":"2024-04-26T06:18:24.822655Z"},"trusted":true},"execution_count":81,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83e55bce2b1143319aa931eee509bc03"}},"metadata":{}},{"name":"stdout","text":"to you unless the recipient consents to their financial institution returning the funds to us and we\nreceive the returned funds; or\n• the amount you told us to pay was less than the amount you needed to pay, you can make another\nPay Anyone payment for the difference.\nYou should notify us immediately if you think that:\n• you have made another type of mistake when making a Pay Anyone payment;\n• you did not authorise a Pay Anyone payment that has been debited to your Account or if you think\na Pay Anyone payment has not been processed in accordance with your instructions;\n• you become aware that a Pay Anyone payment made to a PayID from your Account was directed\nto an incorrect recipient; or\n• you were fraudulently induced to make a Pay Anyone payment.\nWhere we consider it appropriate and we are reasonably able to do so, we may request that the\nfinancial institution to whom the funds were transferred returns the funds to us, on your behalf.\nHowever, this is not always possible. 7.6 Errors\nYou are responsible for checking your Account transaction records and statements to ensure that\nPay Anyone payments have been made correctly.\nYou should advise us as soon as possible if you become aware that you may have made a mistake\nwhen making a Pay Anyone payment.\nIf you instruct us to make a Pay Anyone payment, and you later discover that:\n• the amount you told us to pay was greater than the amount you needed to pay, you must contact\nthe recipient to obtain a refund of the excess. If we processed the Pay Anyone payment as an\nOsko Payment or a Fast Payment, we may be able to request that the funds, or just the overpaid\namount, be returned on your behalf if you ask us to do so. However, the amount will not be returned\nto you unless the recipient consents to their financial institution returning the funds to us and we\nreceive the returned funds; or\n• the amount you told us to pay was less than the amount you needed to pay, you can make another • think you have been fraudulently induced to make a BPAY Payment.\nIf a BPAY Payment is made from your Account without your knowledge or consent, liability for that\nunauthorised BPAY Payment will be determined in accordance with this clause. We will not be liable\nfor any loss or damage you suffer as a result of using the BPAY Scheme unless these terms and\nconditions or an applicable law or industry code provides otherwise.\nMistaken BPAY Payments\nIf a BPAY Payment is made to a Biller or for an amount which is not in accordance with your\ninstructions and your Account was debited for the amount of that payment, we will credit the amount\nof that BPAY Payment to your Account. If you were responsible for the mistake resulting in the BPAY\nPayment and we cannot recover that amount within 20 business days from the date we attempt to\nrecover it, you will be liable for the amount of the BPAY Payment and we may debit it to your Account.\nUnauthorised BPAY Payments to the named and/or intended recipient as a result of your error or you being advised of the wrong\nBSB number and/or identifier, where the financial institution at which the account of the unintended\nrecipient is held is also a subscriber to the ePayments Code; or\n• we process as an Osko Payment or a Fast Payment where funds are paid to the wrong account as\na result of your error, for example if you use or input incorrect payee details accidentally or because\nyou were advised by the payee of the wrong account details or you select an incorrect payee from\na list of potential payees.\nMistaken Internet Payments do not include BPAY payments.\nIf you notify us that you have made a Mistaken Internet Payment we will investigate the matter and\ninform you (in writing) of the outcome within 30 business days from the date you notified us.\nNotification within 10 business days\nIf you notify us of a Mistaken Internet Payment within 10 business days of making the payment, and\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# -- Experimenting...","metadata":{}},{"cell_type":"markdown","source":"### -- Experimenting with knowledge graphs","metadata":{}},{"cell_type":"code","source":"\n# Error: ValueError: The specified LLM does not support the 'with_structured_output'. Please ensure you are using an LLM that supports this feature\n\n# #!pip install langchain-experimental\n# from langchain.llms import LlamaCpp\n# #llm = LlamaCpp(model_path=\"path/to/llama/model\")\n# llm = model\n\n# from langchain_experimental.graph_transformers import LLMGraphTransformer\n# llm_transformer = LLMGraphTransformer(llm=llm)\n\n# from langchain.vectorstores import FAISS\n# vector_store = FAISS.from_texts(texts)\n\n# • Extract graph data from text using the LLMGraphTransformer:\n# from langchain_core.documents import Document\n# doc = Document(text=\"Some text...\")\n# graph_data = llm_transformer.transform(doc)\n\n# • Store the extracted graph data in the vector store:\n# vector_store.add_graph_data(graph_data)","metadata":{"execution":{"iopub.status.busy":"2024-04-26T05:48:36.537049Z","iopub.execute_input":"2024-04-26T05:48:36.537717Z","iopub.status.idle":"2024-04-26T05:48:36.542252Z","shell.execute_reply.started":"2024-04-26T05:48:36.537681Z","shell.execute_reply":"2024-04-26T05:48:36.541350Z"}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### -- Experimenting with alternate semantic search","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:50:27.028963Z","iopub.execute_input":"2024-04-26T06:50:27.029954Z","iopub.status.idle":"2024-04-26T06:50:27.033920Z","shell.execute_reply.started":"2024-04-26T06:50:27.029916Z","shell.execute_reply":"2024-04-26T06:50:27.032982Z"}}},{"cell_type":"code","source":"# ERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\n# ERROR: No matching distribution found for faiss\n\n# !pip install faiss\n# import faiss\n# # Prepare the FAISS index\n# embeddings = np.stack(df3['embeddings'].tolist())\n# index = faiss.IndexFlatIP(embeddings.shape[1])\n# index.add(embeddings)\n\n# # Query the FAISS index\n# question_embedding = model_trans.encode(user, convert_to_tensor=True).cpu().numpy()\n# distances, indices = index.search(question_embedding[None, :], 4)\n\n# # Retrieve the most similar rows\n# most_similar_rows = df3.iloc[indices[0]]","metadata":{"execution":{"iopub.status.busy":"2024-04-26T06:52:23.608890Z","iopub.execute_input":"2024-04-26T06:52:23.609928Z","iopub.status.idle":"2024-04-26T06:52:25.562940Z","shell.execute_reply.started":"2024-04-26T06:52:23.609879Z","shell.execute_reply":"2024-04-26T06:52:25.561835Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stderr","text":"huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n\t- Avoid using `tokenizers` before the fork if possible\n\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n","output_type":"stream"},{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement faiss (from versions: none)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for faiss\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}