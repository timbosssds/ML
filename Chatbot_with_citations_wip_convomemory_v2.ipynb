{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMPMs/7sYAtGZamuajlh9W0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "759cb59aa7314a5985dc20062c80f837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ae553d959b341cdb7a1aaa9b89d0721",
              "IPY_MODEL_da483af4d28c4ef2af6cd899dab36baf",
              "IPY_MODEL_ca43beb21f9f493e89fd9d9350c0204a"
            ],
            "layout": "IPY_MODEL_a2b7f20baa014cc5ad30dc12f1111268"
          }
        },
        "afec53283bc745e5b8ef049ef009b538": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1ebc25302d964caa8400b57073b71fef",
              "IPY_MODEL_14674d4a50ce4a4181205149db726f3e",
              "IPY_MODEL_b3da9355e2ce40469588460fb2a3dcf3"
            ],
            "layout": "IPY_MODEL_16f2d308c29e4577b53374702b9050e5"
          }
        },
        "c134bca13f8e470e91ab25a24a147bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_36d13b5b0800407280a0371c794e54f6",
              "IPY_MODEL_a518b9e7f20446f4a46304cebe553456",
              "IPY_MODEL_edc587e4005b4ed2a3ed0aa959d46743"
            ],
            "layout": "IPY_MODEL_09c23470664b48839fa141e4ceb11e8e"
          }
        },
        "feb41ddf51a346de961f039ebaa78e06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ddd52ca43230438c8ce509ebf8cc6e39",
              "IPY_MODEL_ebdf943835ef47179d569ca6e1b09d39",
              "IPY_MODEL_43efc606bf3f4182b11b093d9fc1d0c7"
            ],
            "layout": "IPY_MODEL_a0719a30c9454bc58e1b97f3f0997163"
          }
        },
        "651c1b93156f4c9aaf4595878fb0a0c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e79a4ab1fce144a78ec8f21da0a8e0a3",
              "IPY_MODEL_2333e168e9a5472489700bac72a5520a",
              "IPY_MODEL_617fc6ce8ae3457bbc00af00dede21e4"
            ],
            "layout": "IPY_MODEL_0574dc9c1ef94298a83175c0dc0121db"
          }
        },
        "fcaf340210b644dfa08394b6d3377f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_666718c088d0465e8adb88f0664a12f3",
              "IPY_MODEL_53ca61272d7c444a9a49f3c25be8736c",
              "IPY_MODEL_801f11813882488cafd5fad6e0a0868a"
            ],
            "layout": "IPY_MODEL_4657c2ce5fc14d64b4763ede3422e813"
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timbosssds/ML/blob/main/Chatbot_with_citations_wip_convomemory_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "# !pip install -qU transformers accelerate einops langchain xformers bitsandbytes faiss-gpu sentence_transformers\n",
        "# !pip install pypdf\n",
        "# !pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XecVz8WVmcvN",
        "outputId": "acd50989-68ae-44e3-8ce5-c09cb22c90ae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.8/211.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.3/45.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-3.17.0-py3-none-any.whl (277 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/277.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-3.17.0\n",
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MileStone 1\n",
        "# -- end-to-end (No Citations)\n",
        "\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "PDF_PATH = '/content/cba_fsg.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "    # Get the page object\n",
        "    page = loader.pages[page_num]\n",
        "    # Extract the texst from the page and add it to the text variable\n",
        "    text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "list_items = texts\n",
        "text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "from transformers import pipeline\n",
        "def generate_answer(question, context):\n",
        "  \"\"\"Generates an answer to a question given a context.\"\"\"\n",
        "  question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "  response = question_answerer(question=question, context=text, max_answer_len=1024, top_p=1)\n",
        "  response = response[list(response)[-1]]\n",
        "  return response\n",
        "\n",
        "# -- Call model and produce answer\n",
        "# Generate an answer to the question\n",
        "#question = \"what is the Eligibility criteria for the Product\"\n",
        "question = \"what is the date\"\n",
        "\n",
        "answer = generate_answer(question, context)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34,
          "referenced_widgets": [
            "759cb59aa7314a5985dc20062c80f837",
            "afec53283bc745e5b8ef049ef009b538",
            "c134bca13f8e470e91ab25a24a147bb8",
            "feb41ddf51a346de961f039ebaa78e06",
            "651c1b93156f4c9aaf4595878fb0a0c7",
            "fcaf340210b644dfa08394b6d3377f8e",
            "4ae553d959b341cdb7a1aaa9b89d0721",
            "da483af4d28c4ef2af6cd899dab36baf",
            "ca43beb21f9f493e89fd9d9350c0204a",
            "a2b7f20baa014cc5ad30dc12f1111268",
            "1ebc25302d964caa8400b57073b71fef",
            "14674d4a50ce4a4181205149db726f3e",
            "b3da9355e2ce40469588460fb2a3dcf3",
            "16f2d308c29e4577b53374702b9050e5",
            "36d13b5b0800407280a0371c794e54f6",
            "a518b9e7f20446f4a46304cebe553456",
            "edc587e4005b4ed2a3ed0aa959d46743",
            "09c23470664b48839fa141e4ceb11e8e",
            "ddd52ca43230438c8ce509ebf8cc6e39",
            "ebdf943835ef47179d569ca6e1b09d39",
            "43efc606bf3f4182b11b093d9fc1d0c7",
            "a0719a30c9454bc58e1b97f3f0997163",
            "e79a4ab1fce144a78ec8f21da0a8e0a3",
            "2333e168e9a5472489700bac72a5520a",
            "617fc6ce8ae3457bbc00af00dede21e4",
            "0574dc9c1ef94298a83175c0dc0121db",
            "666718c088d0465e8adb88f0664a12f3",
            "53ca61272d7c444a9a49f3c25be8736c",
            "801f11813882488cafd5fad6e0a0868a",
            "4657c2ce5fc14d64b4763ede3422e813"
          ]
        },
        "id": "EsfhAbQI5bn-",
        "outputId": "cb2956af-9f1a-40ef-9d6d-4f6cc5d9e3b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "759cb59aa7314a5985dc20062c80f837"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "afec53283bc745e5b8ef049ef009b538"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c134bca13f8e470e91ab25a24a147bb8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "feb41ddf51a346de961f039ebaa78e06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "651c1b93156f4c9aaf4595878fb0a0c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fcaf340210b644dfa08394b6d3377f8e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 October 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDY6-Qga_Jk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MileStone 2\n",
        "# -- end-to-end (With Citations)\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "PDF_PATH = '/content/cba_fsg.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "    # Get the page object\n",
        "    page = loader.pages[page_num]\n",
        "    # Extract the texst from the page and add it to the text variable\n",
        "    text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "list_items = texts\n",
        "text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "# Define a function to generate an answer to a question with citations\n",
        "from transformers import pipeline\n",
        "\n",
        "def generate_answer_with_citations(question, context):\n",
        "    \"\"\"Generates an answer to a question given a context and provides citations.\"\"\"\n",
        "    question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "    response = question_answerer(question=question, context=context, max_answer_len=1024, top_p=1)\n",
        "    answer_text = response[list(response)[-1]]\n",
        "    answer_start = response[\"start\"]\n",
        "    answer_end = response[\"end\"]\n",
        "\n",
        "    # Get the passage containing the answer\n",
        "    start_index = max(0, context.rfind(\".\", 0, answer_start))\n",
        "    end_index = min(len(context), context.find(\".\", answer_end))\n",
        "    passage_with_answer = context[start_index:end_index].strip()\n",
        "\n",
        "    # Get the citation (page number) of the passage\n",
        "    page_number = context.count(\".\", 0, start_index) + 1\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer_text,\n",
        "        \"passage\": passage_with_answer,\n",
        "        \"citation\": f\"Page {page_number}\"\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "#question = \"what is the date\"\n",
        "question = \"what commision do you receive\"\n",
        "answer_info = generate_answer_with_citations(question, context)\n",
        "print(\"Answer:\", answer_info[\"answer\"])\n",
        "print(\"Passage:\", answer_info[\"passage\"])\n",
        "print(\"Citation:\", answer_info[\"citation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qrubmmw_Jem",
        "outputId": "afe869b9-602f-4a86-ad51-23a795f945fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: via email, by telephone or fax\n",
            "Passage: . \n",
            "However, there are special arrangements in place for some \n",
            "products and services where we can receive your instructions \n",
            "electronically via email, by telephone or fax\n",
            "Citation: Page 13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-A0cTHPa5bfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9ZWy1sOItkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsV8zxyXItfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- All below is WIP..."
      ],
      "metadata": {
        "id": "0YEMKfx95bci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F4knbIR2IuHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h65QqB14IuB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP - trying to get conversation history\n",
        "# -- end-to-end (With Citations)\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "PDF_PATH = '/content/cba_fsg.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "  # Get the page object\n",
        "  page = loader.pages[page_num]\n",
        "  # Extract the texst from the page and add it to the text variable\n",
        "  text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "  list_items = texts\n",
        "  text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- 4.0 Maintain conversation history\n",
        "conversation_history = []\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "\n",
        "# Define a function to generate an answer to a question with citations\n",
        "from transformers import pipeline\n",
        "\n",
        "def generate_answer_with_citations(question, context):\n",
        "  \"\"\"Generates an answer to a question given a context and provides citations.\"\"\"\n",
        "  # Check if the question is related to any of the previous questions\n",
        "  for previous_question, previous_answer in conversation_history:\n",
        "    if question.startswith(previous_question):\n",
        "      context = f\"{context} {previous_answer}\"\n",
        "\n",
        "  question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "  response = question_answerer(question=question, context=context, max_answer_len=1024, top_p=1)\n",
        "  answer_text = response[list(response)[-1]]\n",
        "  answer_start = response[\"start\"]\n",
        "  answer_end = response[\"end\"]\n",
        "\n",
        "  # Get the passage containing the answer\n",
        "  start_index = max(0, context.rfind(\".\", 0, answer_start))\n",
        "  end_index = min(len(context), context.find(\".\", answer_end))\n",
        "  passage_with_answer = context[start_index:end_index].strip()\n",
        "\n",
        "  # Get the citation (page number) of the passage\n",
        "  page_number = context.count(\".\", 0, start_index) + 1\n",
        "\n",
        "  # Add the new question and answer to the conversation history\n",
        "  conversation_history.append((question, answer_text))\n",
        "\n",
        "  return {\n",
        "      \"answer\": answer_text,\n",
        "      \"passage\": passage_with_answer,\n",
        "      \"citation\": f\"Page {page_number}\"}\n",
        "\n",
        "# Example usage\n",
        "#question = \"what is the date\" # original question\n",
        "\n",
        "#question = \"what is afca?\" # initial q to test follow up question\n",
        "question = \"what number do i contact you on?\" # follow up question to see if conversation memory working\n",
        "\n",
        "#question = \"what email do i use for dispute resolution?\" # Intial question\n",
        "#question = \"and phone number?\" # Intial question # Follow up\n",
        "\n",
        "answer_info = generate_answer_with_citations(question, context)\n",
        "print(\"Answer:\", answer_info[\"answer\"])\n",
        "print(\"Passage:\", answer_info[\"passage\"])\n",
        "print(\"Citation:\", answer_info[\"citation\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBT83oF8AF5A",
        "outputId": "41c4dba5-20c6-4bd7-c527-c80d1ab7e652"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 1300 555 727\n",
            "Passage: .au/feedback\n",
            "National Relay Service \n",
            "• TTY or Voice: Call 133 677  then as k for 13 2221\n",
            "• Speak & listen: Call 1300 555 727  then as k for 13 2221\n",
            "• SMS relay – Text  0423 677 767\n",
            "For more information, visit the National Relay Service: \n",
            "relayservice\n",
            "Citation: Page 43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td2XSwCfAFym",
        "outputId": "aba434f4-ea0b-4562-fee3-2ac81825dfbb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('what number do i contact you on?', '1300 555 727')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rehELAQ-AFvg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- WIP (trying to use langchain memory)\n",
        "# MileStone 2\n",
        "# -- end-to-end (With Citations)\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "#PDF_PATH = '/content/cba_fsg.pdf'\n",
        "PDF_PATH = '/content/bendigo-term-deposit-accounts-facilities.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "\n",
        "# -- New (add chat memory)\n",
        "# https://python.langchain.com/docs/modules/memory/\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "# -- New (add chat memory)\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "    # Get the page object\n",
        "    page = loader.pages[page_num]\n",
        "    # Extract the texst from the page and add it to the text variable\n",
        "    text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "list_items = texts\n",
        "text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "# Define a function to generate an answer to a question with citations\n",
        "from transformers import pipeline\n",
        "\n",
        "def generate_answer_with_citations(question, context): #, memory\n",
        "    \"\"\"Generates an answer to a question given a context and provides citations.\"\"\"\n",
        "    question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "    response = question_answerer(question=question, context=context, max_answer_len=1024, top_p=1)\n",
        "    answer_text = response[list(response)[-1]]\n",
        "    answer_start = response[\"start\"]\n",
        "    answer_end = response[\"end\"]\n",
        "\n",
        "    # -- New (add chat memory)\n",
        "    #MessagesPlaceholder(variable_name=\"chat_history\")\n",
        "\n",
        "    # Get the passage containing the answer\n",
        "    start_index = max(0, context.rfind(\".\", 0, answer_start))\n",
        "    end_index = min(len(context), context.find(\".\", answer_end))\n",
        "    passage_with_answer = context[start_index:end_index].strip()\n",
        "\n",
        "    # Get the citation (page number) of the passage\n",
        "    page_number = context.count(\".\", 0, start_index) + 1\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer_text,\n",
        "        \"passage\": passage_with_answer,\n",
        "        \"citation\": f\"Page {page_number}\"\n",
        "    }\n",
        "\n",
        "# -- New (add chat memory)\n",
        "#memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
        "\n",
        "# Example usage\n",
        "#question = \"what number do i contact you on?\" # follow up question to see if conversation memory working\n",
        "question = \"what isthe initial deposit?\"\n",
        "#question = \"what email do i use for dispute resolution?\" # Intial question\n",
        "#question = \"and phone number?\" # Intial question # Follow up\n",
        "#answer_info = generate_answer_with_citations(question, context, memory)\n",
        "\n",
        "answer_info = generate_answer_with_citations(question, context)\n",
        "print(\"Answer:\", answer_info[\"answer\"])\n",
        "print(\"Passage:\", answer_info[\"passage\"])\n",
        "print(\"Citation:\", answer_info[\"citation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELVIvz5M6Kw9",
        "outputId": "aa11c7d0-f03a-4b25-f496-a76f35cfa2be"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: the amount you initially deposit with us \n",
            "when you open your account\n",
            "Passage: .  \n",
            " \n",
            "\"initial deposit\"  means the amount you initially deposit with us \n",
            "when you open your account\n",
            "Citation: Page 65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#def generate_answer_with_citations(question, context): #, memory\n",
        "\"\"\"Generates an answer to a question given a context and provides citations.\"\"\"\n",
        "question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "response = question_answerer(question=question, context=context, max_answer_len=1024, top_p=1)\n",
        "answer_text = response[list(response)[-1]]\n",
        "answer_start = response[\"start\"]\n",
        "answer_end = response[\"end\"]\n",
        "\n",
        "# -- New (add chat memory)\n",
        "#MessagesPlaceholder(variable_name=\"chat_history\")\n",
        "\n",
        "# Get the passage containing the answer\n",
        "start_index = max(0, context.rfind(\".\", 0, answer_start))\n",
        "end_index = min(len(context), context.find(\".\", answer_end))\n",
        "passage_with_answer = context[start_index:end_index].strip()\n",
        "\n",
        "# Get the citation (page number) of the passage\n",
        "page_number = context.count(\".\", 0, start_index) + 1\n",
        "print(page_number)\n",
        "\n",
        "    # return {\n",
        "    #     \"answer\": answer_text,\n",
        "    #     \"passage\": passage_with_answer,\n",
        "    #     \"citation\": f\"Page {page_number}\"\n",
        "    # }"
      ],
      "metadata": {
        "id": "WdE7SbWD6Ktt",
        "outputId": "99b6c633-eb9f-4093-ef1d-b31b7bfb6b0d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujMgBwhl2Oc_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Part of embedding - can i make the data to df, then link have text in one col and embeddings in next\n",
        "\n",
        "# Need to get embeddings going...\n",
        "# Bard: python open source code to embed pdf doc as vectors in dataframe\n",
        "\n",
        "# Not sure below required.\n",
        "# import faiss\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import sentence_transformers\n",
        "\n",
        "\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "#PDF_PATH = '/content/cba_fsg.pdf'\n",
        "PDF_PATH = '/content/bendigo-term-deposit-accounts-facilities.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "\n",
        "# -- New (add chat memory)\n",
        "# https://python.langchain.com/docs/modules/memory/\n",
        "from langchain.prompts import (\n",
        "    ChatPromptTemplate,\n",
        "    MessagesPlaceholder,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "\n",
        "# -- New (add chat memory)\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text + now store the text in df.\n",
        "# Once text added to df, call this to add new col with text embeddings.\n",
        "import gensim\n",
        "model = gensim.models.Word2Vec(chunk, min_count=1)\n",
        "embeddings = model.wv.vectors\n",
        "\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "    # Get the page object\n",
        "    page = loader.pages[page_num]\n",
        "    # Extract the texst from the page and add it to the text variable\n",
        "    text += page.extract_text()\n",
        "\n",
        "# Split text into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# Tokenize each chunk\n",
        "tokenized_texts = [text.split() for text in texts]\n",
        "\n",
        "# Train Word2Vec model\n",
        "model = gensim.models.Word2Vec(tokenized_texts, min_count=1)\n",
        "\n",
        "# Function to get embeddings for each word in a chunk\n",
        "def get_embeddings(chunk):\n",
        "    return [model.wv[word] if word in model.wv else None for word in chunk.split()]\n",
        "\n",
        "# Create DataFrame with chunks and their embeddings\n",
        "df = pd.DataFrame(texts, columns=['chunk'])\n",
        "df['embeddings'] = df['chunk'].apply(get_embeddings)\n",
        "\n",
        "# Display DataFrame\n",
        "display(df)\n",
        "print(df.shape)\n",
        "\n",
        "\n",
        "\n",
        "# -- Need to embed question\n",
        "question = \"what is the initial deposit?\"\n",
        "def generate_embeddings(text):\n",
        "  \"\"\"Generates embeddings using the Gensim library.\"\"\"\n",
        "  model = gensim.models.Word2Vec(text, min_count=1)\n",
        "  embeddings = model.wv.vectors\n",
        "  return embeddings\n",
        "q = generate_embeddings(question)\n",
        "dfq = pd.DataFrame([[q]], columns=['data'])\n",
        "dfq['chunk'] = question\n",
        "dfq = dfq[['chunk', 'data']]\n",
        "display(dfq)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5KIKiR3YzYzN",
        "outputId": "b39d8b8b-3caa-4228-9196-01665cb6b257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                                chunk  \\\n",
              "0   Bendigo Term Deposit Accounts and Facilities -...   \n",
              "1   The issuer of the products described in this d...   \n",
              "2   determine the rate of interest we pay on your ...   \n",
              "3   Additional Deposits  Within the first 7 days o...   \n",
              "4   The terms and conditions beginning on page 6 e...   \n",
              "..                                                ...   \n",
              "63  25.1 We can decide, at our discretion, the ord...   \n",
              "64  (e) if you are registered for Bendigo e -banki...   \n",
              "65  debt. Any reasonable expenses we incur in reco...   \n",
              "66  conditions that is illegal or unenforceable wi...   \n",
              "67  to be sent to you.  \\n \\n \\n  Bendigo Term Dep...   \n",
              "\n",
              "                                           embeddings  \n",
              "0   [[-0.08560844, 0.148259, 0.048547424, -0.07217...  \n",
              "1   [[-0.063090034, 0.0969673, 0.033387315, -0.032...  \n",
              "2   [[0.0026926412, 0.0012637266, -0.0021947091, -...  \n",
              "3   [[0.0001396415, 0.014425261, -0.0045510964, 0....  \n",
              "4   [[-0.063090034, 0.0969673, 0.033387315, -0.032...  \n",
              "..                                                ...  \n",
              "63  [[0.0020451718, 0.008724767, 0.006376833, 0.00...  \n",
              "64  [[-0.0056517087, 0.015433809, -0.0027306234, -...  \n",
              "65  [[-0.0018903115, -0.00023423944, -0.009434234,...  \n",
              "66  [[-0.042209182, 0.079314075, 0.013568966, -0.0...  \n",
              "67  [[-0.17456013, 0.31856096, 0.07822075, -0.1338...  \n",
              "\n",
              "[68 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c3c4f9f9-aa6e-4a8f-9dfd-6f7ef3139973\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Bendigo Term Deposit Accounts and Facilities -...</td>\n",
              "      <td>[[-0.08560844, 0.148259, 0.048547424, -0.07217...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The issuer of the products described in this d...</td>\n",
              "      <td>[[-0.063090034, 0.0969673, 0.033387315, -0.032...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>determine the rate of interest we pay on your ...</td>\n",
              "      <td>[[0.0026926412, 0.0012637266, -0.0021947091, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Additional Deposits  Within the first 7 days o...</td>\n",
              "      <td>[[0.0001396415, 0.014425261, -0.0045510964, 0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The terms and conditions beginning on page 6 e...</td>\n",
              "      <td>[[-0.063090034, 0.0969673, 0.033387315, -0.032...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>25.1 We can decide, at our discretion, the ord...</td>\n",
              "      <td>[[0.0020451718, 0.008724767, 0.006376833, 0.00...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>(e) if you are registered for Bendigo e -banki...</td>\n",
              "      <td>[[-0.0056517087, 0.015433809, -0.0027306234, -...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>debt. Any reasonable expenses we incur in reco...</td>\n",
              "      <td>[[-0.0018903115, -0.00023423944, -0.009434234,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>conditions that is illegal or unenforceable wi...</td>\n",
              "      <td>[[-0.042209182, 0.079314075, 0.013568966, -0.0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>to be sent to you.  \\n \\n \\n  Bendigo Term Dep...</td>\n",
              "      <td>[[-0.17456013, 0.31856096, 0.07822075, -0.1338...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>68 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c3c4f9f9-aa6e-4a8f-9dfd-6f7ef3139973')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c3c4f9f9-aa6e-4a8f-9dfd-6f7ef3139973 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c3c4f9f9-aa6e-4a8f-9dfd-6f7ef3139973');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-068b4bc1-5714-47ce-be43-c980b785fc0d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-068b4bc1-5714-47ce-be43-c980b785fc0d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-068b4bc1-5714-47ce-be43-c980b785fc0d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68, 2)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                          chunk  \\\n",
              "0  what is the initial deposit?   \n",
              "\n",
              "                                                data  \n",
              "0  [[-0.00053622725, 0.00023643136, 0.0051033497,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9cd59b81-bbee-430c-b889-f02ca928157a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chunk</th>\n",
              "      <th>data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what is the initial deposit?</td>\n",
              "      <td>[[-0.00053622725, 0.00023643136, 0.0051033497,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9cd59b81-bbee-430c-b889-f02ca928157a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9cd59b81-bbee-430c-b889-f02ca928157a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9cd59b81-bbee-430c-b889-f02ca928157a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y65bLpowCRMl"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- Search df to find best context\n",
        "import numpy as np\n",
        "target_row = dfq.iloc[0]\n",
        "def cosine_similarity(row1, row2):\n",
        "    # Calculate the dot product of the two vectors\n",
        "    dot_product = np.dot(row1, row2)\n",
        "    # Calculate the norm of each vector\n",
        "    norm1 = np.linalg.norm(row1)\n",
        "    norm2 = np.linalg.norm(row2)\n",
        "    # Calculate the cosine similarity\n",
        "    cosine_similarity = dot_product / (norm1 * norm2)\n",
        "    return cosine_similarity\n",
        "\n",
        "similarity_scores = []\n",
        "for index, row in df.iterrows():\n",
        "    similarity_score = cosine_similarity(row, target_row)\n",
        "    similarity_scores.append(similarity_score)\n",
        "similarity_df = pd.DataFrame(similarity_scores, columns=['similarity_score'])\n",
        "top_n_df = similarity_df.sort_values(by='similarity_score', ascending=False).head(n)\n",
        "top_n_similar_rows = df1.merge(top_n_df, on='index')\n",
        "# -- The pass both to model"
      ],
      "metadata": {
        "id": "aQknWGuj4DJn",
        "outputId": "70c7a6b6-c0f3-4683-ed0b-943798ab9071",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-65-53c2bde92f4f>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0msimilarity_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0msimilarity_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_row\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0msimilarity_scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0msimilarity_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimilarity_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'similarity_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-65-53c2bde92f4f>\u001b[0m in \u001b[0;36mcosine_similarity\u001b[0;34m(row1, row2)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcosine_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Calculate the dot product of the two vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdot_product\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;31m# Calculate the norm of each vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnorm1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'str'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0YH_BtJ8_tF7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V568-0wPBeg7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}