{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQllE0OzvIMva1lsOMPgmT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/timbosssds/ML/blob/main/Chatbot_with_citations_wip_convomemory.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required libraries\n",
        "#!pip install -qU transformers accelerate einops langchain xformers bitsandbytes faiss-gpu sentence_transformers\n",
        "#!pip install pypdf\n",
        "#!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XecVz8WVmcvN",
        "outputId": "7af951de-9f2c-4909-c417-c70fe7a28088"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MileStone 1\n",
        "# -- end-to-end (No Citations)\n",
        "\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "PDF_PATH = '/content/cba_fsg.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "    # Get the page object\n",
        "    page = loader.pages[page_num]\n",
        "    # Extract the texst from the page and add it to the text variable\n",
        "    text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "list_items = texts\n",
        "text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "from transformers import pipeline\n",
        "def generate_answer(question, context):\n",
        "  \"\"\"Generates an answer to a question given a context.\"\"\"\n",
        "  question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "  response = question_answerer(question=question, context=text, max_answer_len=1024, top_p=1)\n",
        "  response = response[list(response)[-1]]\n",
        "  return response\n",
        "\n",
        "# -- Call model and produce answer\n",
        "# Generate an answer to the question\n",
        "#question = \"what is the Eligibility criteria for the Product\"\n",
        "question = \"what is the date\"\n",
        "\n",
        "answer = generate_answer(question, context)\n",
        "print(answer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsfhAbQI5bn-",
        "outputId": "ca40ef38-d213-4867-972c-c9f037ec0398"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 October 2022\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jDY6-Qga_Jk6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MileStone 2\n",
        "# -- end-to-end (With Citations)\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "PDF_PATH = '/content/cba_fsg.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "    # Get the page object\n",
        "    page = loader.pages[page_num]\n",
        "    # Extract the texst from the page and add it to the text variable\n",
        "    text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "list_items = texts\n",
        "text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "# Define a function to generate an answer to a question with citations\n",
        "from transformers import pipeline\n",
        "\n",
        "def generate_answer_with_citations(question, context):\n",
        "    \"\"\"Generates an answer to a question given a context and provides citations.\"\"\"\n",
        "    question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "    response = question_answerer(question=question, context=context, max_answer_len=1024, top_p=1)\n",
        "    answer_text = response[list(response)[-1]]\n",
        "    answer_start = response[\"start\"]\n",
        "    answer_end = response[\"end\"]\n",
        "\n",
        "    # Get the passage containing the answer\n",
        "    start_index = max(0, context.rfind(\".\", 0, answer_start))\n",
        "    end_index = min(len(context), context.find(\".\", answer_end))\n",
        "    passage_with_answer = context[start_index:end_index].strip()\n",
        "\n",
        "    # Get the citation (page number) of the passage\n",
        "    page_number = context.count(\".\", 0, start_index) + 1\n",
        "\n",
        "    return {\n",
        "        \"answer\": answer_text,\n",
        "        \"passage\": passage_with_answer,\n",
        "        \"citation\": f\"Page {page_number}\"\n",
        "    }\n",
        "\n",
        "# Example usage\n",
        "question = \"what is the date\"\n",
        "answer_info = generate_answer_with_citations(question, context)\n",
        "print(\"Answer:\", answer_info[\"answer\"])\n",
        "print(\"Passage:\", answer_info[\"passage\"])\n",
        "print(\"Citation:\", answer_info[\"citation\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Qrubmmw_Jem",
        "outputId": "4b2364b7-1032-4674-ba4e-c659ac3a73b2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: 1 October 2022\n",
            "Passage: .\n",
            "Dated 1 October 2022\n",
            "We are required under the Corporations Act to \n",
            "provide you with the following  information:\n",
            "This Financial Services Guide (FSG) is issued by \n",
            "Commonwealth Bank of Australia (‘Bank’, ‘we’, \n",
            "‘our’ or ‘us’) and is intended to provide you with \n",
            "information that will assist you in making informed \n",
            "decisions on whether you want to use our products \n",
            "and services\n",
            "Citation: Page 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-A0cTHPa5bfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m9ZWy1sOItkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xsV8zxyXItfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- All below is WIP..."
      ],
      "metadata": {
        "id": "0YEMKfx95bci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "F4knbIR2IuHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h65QqB14IuB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WIP - trying to get conversation history\n",
        "# -- end-to-end (With Citations)\n",
        "# -- 1.0 Load the PDF document\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "import PyPDF2\n",
        "#PDF_PATH = open(r'/content/cba_fsg.pdf', mode='rb')\n",
        "PDF_PATH = '/content/cba_fsg.pdf'\n",
        "loader = PyPDF2.PdfReader(PDF_PATH)\n",
        "\n",
        "# -- 2.0 Create an empty string to store the text\n",
        "text = \"\"\n",
        "# Loop through each page of the PDF\n",
        "for page_num in range(len(loader.pages)):\n",
        "  # Get the page object\n",
        "  page = loader.pages[page_num]\n",
        "  # Extract the texst from the page and add it to the text variable\n",
        "  text += page.extract_text()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_text(text)\n",
        "\n",
        "# -- 3.0 Process text\n",
        "def convert_list_to_string_with_speech_marks(list_items):\n",
        "  \"\"\"Converts a list to a string with speech marks at each end.\"\"\"\n",
        "  string = \" \".join(list_items)\n",
        "  string = f\"\\\"{string}\\\"\"\n",
        "  return string\n",
        "  list_items = texts\n",
        "  text = convert_list_to_string_with_speech_marks(list_items)\n",
        "\n",
        "# -- 4.0 Maintain conversation history\n",
        "conversation_history = []\n",
        "\n",
        "# -- Model\n",
        "context=text\n",
        "\n",
        "# Define a function to generate an answer to a question with citations\n",
        "from transformers import pipeline\n",
        "\n",
        "def generate_answer_with_citations(question, context):\n",
        "  \"\"\"Generates an answer to a question given a context and provides citations.\"\"\"\n",
        "  # Check if the question is related to any of the previous questions\n",
        "  for previous_question, previous_answer in conversation_history:\n",
        "    if question.startswith(previous_question):\n",
        "      context = f\"{context} {previous_answer}\"\n",
        "\n",
        "  question_answerer = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")\n",
        "  response = question_answerer(question=question, context=context, max_answer_len=1024, top_p=1)\n",
        "  answer_text = response[list(response)[-1]]\n",
        "  answer_start = response[\"start\"]\n",
        "  answer_end = response[\"end\"]\n",
        "\n",
        "  # Get the passage containing the answer\n",
        "  start_index = max(0, context.rfind(\".\", 0, answer_start))\n",
        "  end_index = min(len(context), context.find(\".\", answer_end))\n",
        "  passage_with_answer = context[start_index:end_index].strip()\n",
        "\n",
        "  # Get the citation (page number) of the passage\n",
        "  page_number = context.count(\".\", 0, start_index) + 1\n",
        "\n",
        "  # Add the new question and answer to the conversation history\n",
        "  conversation_history.append((question, answer_text))\n",
        "\n",
        "  return {\n",
        "      \"answer\": answer_text,\n",
        "      \"passage\": passage_with_answer,\n",
        "      \"citation\": f\"Page {page_number}\"}\n",
        "\n",
        "# Example usage\n",
        "#question = \"what is the date\" # original question\n",
        "\n",
        "#question = \"what is your GPO box number?\" # initial q to test follow up question\n",
        "question = \"what state is that in?\" # follow up question to see if conversation memory working\n",
        "answer_info = generate_answer_with_citations(question, context)\n",
        "print(\"Answer:\", answer_info[\"answer\"])\n",
        "print(\"Passage:\", answer_info[\"passage\"])\n",
        "print(\"Citation:\", answer_info[\"citation\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBT83oF8AF5A",
        "outputId": "4f4fe717-7a8e-4794-f72c-c164e0b4d318"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Answer: Colonial First State\n",
            "Passage: .\n",
            "2  Avanteos Investments Limited is a subsidiary of Superannuation and \n",
            "Investments HoldCo Pty Limited ABN 64 644 660 882 (HoldCo) and is \n",
            "part of Colonial First State, which refers to HoldCo and its subsidiaries\n",
            "Citation: Page 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversation_history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Td2XSwCfAFym",
        "outputId": "608affb4-2f96-439c-c2c2-f458e3eca54f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('what is your GPO box number?', '2719')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rehELAQ-AFvg"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qBhy4xsM6Kz9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ELVIvz5M6Kw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WdE7SbWD6Ktt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujMgBwhl2Oc_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}